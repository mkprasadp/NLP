{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb33b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df37ad4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he is\n",
      "he is considering\n",
      "he is considering a\n",
      "he is considering a leveraged\n",
      "he is considering a leveraged buyout\n",
      "he is considering a leveraged buyout of\n",
      "he is considering a leveraged buyout of the\n",
      "he is considering a leveraged buyout of the equity\n",
      "he is considering a leveraged buyout of the equity in\n",
      "he is considering a leveraged buyout of the equity in current\n",
      "he is considering a leveraged buyout of the equity in current year\n",
      "he is considering a leveraged buyout of the equity in current year includes\n",
      "he is considering a leveraged buyout of the equity in current year includes extraordinary\n",
      "he is considering a leveraged buyout of the equity in current year includes extraordinary gain\n",
      "he is considering a leveraged buyout of the equity in current year includes extraordinary gain of\n",
      "he is considering a leveraged buyout of the equity in current year includes extraordinary gain of nine\n",
      "he is considering a leveraged buyout of the equity in current year includes extraordinary gain of nine indicators\n",
      "he is considering a leveraged buyout of the equity in current year includes extraordinary gain of nine indicators were\n",
      "he is considering a leveraged buyout of the equity in current year includes extraordinary gain of nine indicators were positive\n",
      "he is considering a leveraged buyout of the equity in current year includes extraordinary gain of nine indicators were positive signs\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, reuters\n",
    "from collections import Counter, defaultdict\n",
    "from nltk import FreqDist, ngrams\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('reuters')\n",
    "sents = reuters.sents()\n",
    "stop_word = set(stopwords.words('english'))\n",
    "string.punctuation = string.punctuation + ' \" ' + ' \" ' + ' - ' + ' _ '\n",
    "removal_list = list(stop_word) + list(string.punctuation) + ['\\t', 'rt']\n",
    "unigram = []\n",
    "bigram = []\n",
    "trigram = []\n",
    "tokenized_text = []\n",
    "for sentence in sents:\n",
    "    sentence = list(map(lambda x: x.lower(), sentence))\n",
    "    for word in sentence:\n",
    "        if word == '.':\n",
    "            sentence.remove(word)\n",
    "        else:\n",
    "            unigram.append(word)\n",
    "            tokenized_text.append(word)\n",
    "    bigram.extend(list(ngrams(sentence, 2, pad_left=True, pad_right=True)))\n",
    "    trigram.extend(list(ngrams(sentence, 3, pad_left=True, pad_right=True)))\n",
    "def remove_stopwords(x):\n",
    "    y = []\n",
    "    for item in x:\n",
    "        if isinstance(item, tuple):\n",
    "            count = 0\n",
    "            for word in item:\n",
    "                if word not in removal_list:\n",
    "                    count = 1\n",
    "                    break\n",
    "            if count == 1:\n",
    "                y.append(item)\n",
    "        else:\n",
    "            if item not in removal_list:\n",
    "                y.append(item)\n",
    "    return y\n",
    "\n",
    "unigram = remove_stopwords(unigram)\n",
    "bigram = remove_stopwords(bigram)\n",
    "trigram = remove_stopwords(trigram)\n",
    "freq_uni = FreqDist(unigram)\n",
    "freq_bi = FreqDist(bigram)\n",
    "freq_tri = FreqDist(trigram)\n",
    "d = defaultdict(Counter)\n",
    "for a, b, c in freq_tri:\n",
    "    if (a is not None) and (b is not None) and (c is not None):\n",
    "        d[a, b][c] += freq_tri[a, b, c]\n",
    "def pick_word(counter):\n",
    "    \"choose a random element\"\n",
    "    return random.choice(list(counter.elements()))\n",
    "prefix = \"he\", \"is\"\n",
    "print(\" \".join(prefix))\n",
    "s = \" \".join(prefix)\n",
    "for i in range(19):\n",
    "    if prefix in d:\n",
    "        suffix = pick_word(d[prefix])\n",
    "        s = s + ' ' + suffix\n",
    "        print(s)\n",
    "        prefix = prefix[1], suffix\n",
    "    else:\n",
    "        print(f\"Prefix {prefix} not found in dictionary. Stopping text generation.\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
